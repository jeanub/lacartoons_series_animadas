{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kCU_54Rwh6Fj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imvWxyw9Myuw"
      },
      "source": [
        "Extraer Datos en la Categoria \"Cartoon Network\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkP2gTf-Ffen",
        "outputId": "7c0ece31-97f5-47b7-b166-9bd7238abfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=2\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=3\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=4\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=5\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=6\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=7\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=2&page=8\n",
            "                                 Nombre            Canal   Año Valoracion\n",
            "0                       2 Perros Tontos  Cartoon Network  1993          7\n",
            "1                Caballeros del Zodiaco  Cartoon Network  1986          8\n",
            "2  El Capitán Planeta y los planetarios  Cartoon Network  1990          7\n",
            "3                            Code Lyoko  Cartoon Network  2003          7\n",
            "4               Coraje El Perro Cobarde  Cartoon Network  1996          8\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=2&page=2\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=2\"\n",
        "num_pages = 8\n",
        "all_data1 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcadorSeries marcador-cartoon\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data1.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data1)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSCx3JzwNWMJ"
      },
      "source": [
        "Extraer Datos en la Categoria \"Nickelodeon\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU4pUG7zNbez",
        "outputId": "a27a6c86-5f3c-45e7-f9ca-1d329f118a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=1&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=1&page=2\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=1&page=3\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=1&page=4\n",
            "                       Nombre        Canal   Año Valoracion\n",
            "0                         Alf  Nickelodeon  1986          7\n",
            "1   Avatar La Leyenda de Aang  Nickelodeon  2005          9\n",
            "2  Avatar La Leyenda de Korra  Nickelodeon  2012          9\n",
            "3                 Bob Esponja  Nickelodeon  1999          8\n",
            "4                      CatDog  Nickelodeon  1998          7\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=1\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=1\"\n",
        "num_pages = 4\n",
        "all_data2 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcadorSeries marcador-nickelodeon\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data2.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data2)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rlU6kj9OXCv"
      },
      "source": [
        "Extraer Datos en la Categoria \"Disney\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx-QfejxOZrT",
        "outputId": "a60e256e-3447-497f-e383-5109d44ce51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=5&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=5&page=2\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=5&page=3\n",
            "                      Nombre   Canal   Año Valoracion\n",
            "0      50 Clasicos de Disney  Disney  1937          8\n",
            "1   Aladdin La serie Animada  Disney  1992          7\n",
            "2  La Sirenita Serie Animada  Disney  1992          7\n",
            "3             Pato Aventuras  Disney  1987          8\n",
            "4               101 Dalmatas  Disney  2018          6\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=5\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=5\"\n",
        "num_pages = 3\n",
        "all_data3 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcadorSeries marcador-disney\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data3.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data3)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wg_9cOQPB7Y"
      },
      "source": [
        "Extraer Datos en la Categoria \"Warner Channel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_uOFB-IPHhT",
        "outputId": "97b937da-a30d-4ac2-ba50-f229a575edc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=6&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=6&page=2\n",
            "                     Nombre           Canal   Año Valoracion\n",
            "0         Batman Del Futuro  Warner Channel  1999          8\n",
            "1   Batman La Serie Animada  Warner Channel  1992          9\n",
            "2       El Mundo De Beakman  Warner Channel  1992          9\n",
            "3  Jumanji La Serie Animada  Warner Channel  1996          6\n",
            "4   Pinky, Elvira y Cerebro  Warner Channel  1998          6\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=6\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=6\"\n",
        "num_pages = 2\n",
        "all_data4 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcador-warner\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data4.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data4)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaf-YsC1QF1e"
      },
      "source": [
        "Extraer Datos en la Categoria \"Fox Kids\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hbMIU8XQN50",
        "outputId": "297f3a76-3805-405e-e3b2-335449922606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=3&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=3&page=2\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=3&page=3\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=3&page=4\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=3&page=5\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=3&page=6\n",
            "                      Nombre     Canal   Año Valoracion\n",
            "0                   BeyBlade  Fox Kids  2001          7\n",
            "1                  Capitán N  Fox Kids  1989          6\n",
            "2  Digimon: Digital Monsters  Fox Kids  1999          7\n",
            "3       Digimon Adventure 02  Fox Kids  2000          8\n",
            "4           Digimon 3 Tamers  Fox Kids  2001          8\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=3\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=3\"\n",
        "num_pages = 6\n",
        "all_data5 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcadorSeries marcador-foxKids\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data5.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data5)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4M_ytLqhXCa"
      },
      "source": [
        "Extraer Datos de \"Hanna Barbera\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zinwSxrrhcYM",
        "outputId": "024d9c6e-37fa-40f9-8d00-97fa04e43873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=4&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=4&page=2\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=4&page=3\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=4&page=4\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=4&page=5\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=4&page=6\n",
            "                           Nombre          Canal   Año Valoracion\n",
            "0                 Canuto y Canito  Hanna Barbera  1959          7\n",
            "1      Clue Club: Buscando Pistas  Hanna Barbera  1977          7\n",
            "2   Dino Boy: En El Valle Perdido  Hanna Barbera  1966          7\n",
            "3         El Fantasma Del Espacio  Hanna Barbera  1966          8\n",
            "4  Drack Pack: El Grupo Increible  Hanna Barbera  1980          7\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=4\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=4\"\n",
        "num_pages = 6\n",
        "all_data6 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcadorSeries marcador-hanna\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data6.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data6)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0bx7SjxjfOk"
      },
      "source": [
        "Extaer Datos en \"Marvel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efDZzBOei7Uu",
        "outputId": "f3a30311-d7d2-4725-a0d9-7542fe25b36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=7&page=1\n",
            "                                                 Nombre   Canal   Año Valoracion\n",
            "0  Los Vengadores: Los Héroes Más Poderosos Del Planeta  Marvel  2010          8\n",
            "1                                                 Blade  Marvel  2011          7\n",
            "2                                           X-Men Anime  Marvel  2011          8\n",
            "3                                       Iron Man: Anime  Marvel  2010          7\n",
            "4                                     El Increible Hulk  Marvel  1996          7\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=7\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=7\"\n",
        "num_pages = 1\n",
        "all_data7 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcador-marvel\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data7.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data7)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XncLMILNjjIL"
      },
      "source": [
        "Extraer Datos en \"Otros\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs0Ct6IvjlyM",
        "outputId": "392baf6a-c961-4072-bcb1-4889bf765294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando página: https://www.lacartoons.com/?Categoria_id=8&page=1\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=8&page=2\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=8&page=3\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=8&page=4\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=8&page=5\n",
            "Procesando página: https://www.lacartoons.com/?Categoria_id=8&page=6\n",
            "             Nombre  Canal   Año Valoracion\n",
            "0  El Fantasma 2040  Otros  1994          7\n",
            "1            Gi Joe  Otros  1985          8\n",
            "2     Street Sharks  Otros  1994          6\n",
            "3   Detective Conan  Otros  1996          8\n",
            "4             Heidi  Otros  1974          8\n"
          ]
        }
      ],
      "source": [
        "#https://www.lacartoons.com/?Categoria_id=8\n",
        "url_base = \"https://www.lacartoons.com/?Categoria_id=8\"\n",
        "num_pages = 6\n",
        "all_data8 = []\n",
        "\n",
        "for page_num in range(1, num_pages + 1):\n",
        "    url_pagina = f\"{url_base}&page={page_num}\"\n",
        "    print(f\"Procesando página: {url_pagina}\")\n",
        "    try:\n",
        "        response = requests.get(url_pagina)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titulos = soup.find_all('p', class_=\"nombre-serie\")\n",
        "        canales = soup.find_all('span', class_=\"marcador marcador-otros\")\n",
        "        años = soup.find_all('span', class_=\"marcador marcador-ano\")\n",
        "        valoraciones = soup.find_all('span', class_=\"valoracion\")\n",
        "\n",
        "        nombre_series = [titulo.text.strip() for titulo in titulos]\n",
        "        canales_series = [canale.text.strip() for canale in canales]\n",
        "        años_series = [año.text.strip() for año in años]\n",
        "        valoraciones_series = [valoracion.text.strip() for valoracion in valoraciones]\n",
        "\n",
        "        # Asumiendo que la cantidad de elementos en cada lista es la misma por página\n",
        "        for i in range(len(nombre_series)):\n",
        "            all_data8.append({\n",
        "                'Nombre': nombre_series[i],\n",
        "                'Canal': canales_series[i] if i < len(canales_series) else None,\n",
        "                'Año': años_series[i] if i < len(años_series) else None,\n",
        "                'Valoracion': valoraciones_series[i] if i < len(valoraciones_series) else None\n",
        "            })\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al obtener la página {page_num}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar la página {page_num}: {e}\")\n",
        "\n",
        "df = pd.DataFrame(all_data8)\n",
        "print(df.head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeVjyniYlZMq"
      },
      "source": [
        "Union de los dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LWjukCEHm88C",
        "outputId": "6af5b111-184b-4eeb-b4a6-b4da847a5162"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nombre</th>\n",
              "      <th>Canal</th>\n",
              "      <th>Año</th>\n",
              "      <th>Valoracion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2 Perros Tontos</td>\n",
              "      <td>Cartoon Network</td>\n",
              "      <td>1993</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Caballeros del Zodiaco</td>\n",
              "      <td>Cartoon Network</td>\n",
              "      <td>1986</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>El Capitán Planeta y los planetarios</td>\n",
              "      <td>Cartoon Network</td>\n",
              "      <td>1990</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Code Lyoko</td>\n",
              "      <td>Cartoon Network</td>\n",
              "      <td>2003</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coraje El Perro Cobarde</td>\n",
              "      <td>Cartoon Network</td>\n",
              "      <td>1996</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>La Familia Robinson</td>\n",
              "      <td>Otros</td>\n",
              "      <td>1981</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>Sabrina Secretos De La Brujita</td>\n",
              "      <td>Otros</td>\n",
              "      <td>2003</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>Pelswick</td>\n",
              "      <td>Otros</td>\n",
              "      <td>2000</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>Naruto shippuden</td>\n",
              "      <td>Otros</td>\n",
              "      <td>2007</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>Jem y Los Hologramas</td>\n",
              "      <td>Otros</td>\n",
              "      <td>1985</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>510 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Nombre            Canal   Año Valoracion\n",
              "0                         2 Perros Tontos  Cartoon Network  1993          7\n",
              "1                  Caballeros del Zodiaco  Cartoon Network  1986          8\n",
              "2    El Capitán Planeta y los planetarios  Cartoon Network  1990          7\n",
              "3                              Code Lyoko  Cartoon Network  2003          7\n",
              "4                 Coraje El Perro Cobarde  Cartoon Network  1996          8\n",
              "..                                    ...              ...   ...        ...\n",
              "505                   La Familia Robinson            Otros  1981          7\n",
              "506        Sabrina Secretos De La Brujita            Otros  2003          6\n",
              "507                              Pelswick            Otros  2000          7\n",
              "508                      Naruto shippuden            Otros  2007          9\n",
              "509                  Jem y Los Hologramas            Otros  1985          7\n",
              "\n",
              "[510 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data = pd.concat([pd.DataFrame(data) for data in [all_data1, all_data2, all_data3, all_data4, all_data5, all_data6, all_data7, all_data8]], ignore_index=True)\n",
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ORXWKO2zrZ-c"
      },
      "outputs": [],
      "source": [
        "all_data.to_csv('Todas las Series de la pagina LACartoons', index=False, encoding='utf-8')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
